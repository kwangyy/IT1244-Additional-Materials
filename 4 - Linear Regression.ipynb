{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Materials Part 4: Linear Regression\n",
    "\n",
    "We will tackle the second ML model learnt in IT1244 called Linear Regression. This is essential for regression problems, which are different from classification and clustering problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "housing = pd.read_csv(\"data/housing_cleaned.csv\", index_col = 'Unnamed: 0')\n",
    "\n",
    "X = housing.drop(\"median_house_value\", axis = 1) \n",
    "y = housing[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initialisation of models\n",
    "\n",
    "By this part, you should have learnt how to manipulate data in Pandas (with the other supplementary materials) or with NumPy. \n",
    "\n",
    "As a recap, the workflow of models usually goes like this:\n",
    "1. Find the model from sklearn - it's usually in a separate library\n",
    "2. do a train test split on the data (80/20? 70/30? up to you)\n",
    "3. fit the data onto the training data\n",
    "4. predict the results using the test data \n",
    "5. compare the predictions against the y values of test data\n",
    "\n",
    "How do we apply this for Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression is taken from sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We will then split the data into different datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Save the model into a variable \n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the data onto training data\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict results using test data\n",
    "predictions = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Metrics\n",
    "\n",
    "As mentioned above, we compare the predictions against the y values of test data. How do we know if a regression model is good? This is where metrics come in.\n",
    "\n",
    "There are mainly three kinds of metrics:\n",
    "1. Mean Squared Error (MSE) - euclidean distance between the predicted and actual data, squared\n",
    "2. Mean Average Error (MAE) - \n",
    "3. Root Mean Squared Error (RMSE) - MSE, but squared root!\n",
    "\n",
    "Depending on what you want to measure from your regression model, you will have to pick the metrics carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:0.11040202545242539 \n",
      "MAE: 0.25171619872349976 \n",
      "RMSE:0.3322680024504698\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# I have created a function just to make it a lot easier to show stuff:\n",
    "def print_regression_metrics(y_pred, y_test):\n",
    "\n",
    "    # Remember we have it such that the predicted column is scaled down with np.log1p\n",
    "    # We need the opposing function, np.expm1 \n",
    "    mse_score = mean_squared_error(y_pred, y_test)\n",
    "    mae_score = mean_absolute_error(y_pred, y_test)\n",
    "    rmse_score = mse_score ** 0.5 \n",
    "\n",
    "    print(f\"MSE:{mse_score} \\nMAE: {mae_score} \\nRMSE:{rmse_score}\")\n",
    "    return \n",
    "\n",
    "# You know what to do if you want it to return the regression metrics! \n",
    "print_regression_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell that for this, MSE works way better and RMSE doesn't make sense since MSE is < 1. (Think why?)\n",
    "\n",
    "### What is the difference between MSE and MAE?\n",
    "MSE means Mean Squared Error, while MAE means Mean Absolute Error.\n",
    "\n",
    "MSE is the value calculated from the __summation of the squared differences__ between the predicted values and the actual values divided by the number of data points.\n",
    "\n",
    "MAE is the value calculated from the __summation of the absolute differences__ between the predicted values and the actual values divided by the number of data points.\n",
    "\n",
    "### Formulas:\n",
    "MSE is calculated as: \n",
    "\n",
    "\\[ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 \\]\n",
    "\n",
    "Meanwhile, MAE is calculated as:\n",
    "\n",
    "\\[ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}| \\]\n",
    "\n",
    "(if you can't see what the formulas are, refer to the github!)\n",
    "\n",
    "### When do i use MSE and MAE?\n",
    "MSE:\n",
    "- Heavily penalises large errors, making it sensitive to outliers\n",
    "- Emphasizes larger errors more than smaller errors.\n",
    "\n",
    "MAE:\n",
    "- Does not heavily penalise large error, making it more robust to outliers\n",
    "- Gives equal weight to all erorrs and treats them equally.\n",
    "\n",
    "Think about why MSE and MAE have these properties! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Further reading\n",
    "\n",
    "For this lesson, I will be going through the simplest regression model, which is Linear Regression. If you're interested in other kinds of regressions, do know that state-of-the-art methods can do regressions too! But if you're looking for something a little bit more traditional, do read up on:\n",
    "\n",
    "- Lasso Regression\n",
    "- Ridge Regression\n",
    "- Elastic Net Regression \n",
    "\n",
    "You may or may not use these in your projects, but you will have to explain how these differ from the normal linear regression - you have been warned.\n",
    "\n",
    "See you next lesson :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
